{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc0a675b",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "\n",
    "---\n",
    "\n",
    "Use this to explore database and query smaller tables for later analysis.\n",
    "\n",
    "Save queries intended for further analysis in 'data/' so you do not have to run the query every time.\n",
    "\n",
    "We should be able to query subsets of this data that will be small enough to store in RAM\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "fcf8fd5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T05:20:15.556232Z",
     "start_time": "2025-11-01T05:20:11.096272Z"
    }
   },
   "source": [
    "import os\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "#from sentence_transformers import SentenceTransformer\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# os.getcwd()\n",
    "\n",
    "## CONNECT TO DB ##\n",
    "# access data on disk by explicitly passing db file\n",
    "# db and query results will be stored on-disk instead of RAM\n",
    "# storing results as pandas df will use RAM normally\n",
    "con = duckdb.connect(\"../data/database.sqlite\")\n",
    "\n",
    "\n",
    "## QUERY FUNCTION ##\n",
    "# simple query function for initital exploration\n",
    "# feel free to add functionality to this\n",
    "def simple_query(query, params=None):\n",
    "    # optional params for easy sanitized inputs\n",
    "    # use ? in query to pass variables safely into query\n",
    "    # pass params as list of variable names to be passed to query\n",
    "    # results are pandas df\n",
    "    result = con.execute(query, params or []).fetchdf()\n",
    "    return result\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Query Data",
   "id": "d09f75790e43ca21"
  },
  {
   "cell_type": "code",
   "id": "9b9354bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T03:22:51.524864Z",
     "start_time": "2025-11-01T03:22:46.947181Z"
    }
   },
   "source": [
    "query = \"\"\"\n",
    "select * from May2015\n",
    "where subreddit = 'politics'\n",
    "\"\"\"\n",
    "politics = simple_query(query)"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Query interrupted",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 5\u001B[0m\n\u001B[0;32m      1\u001B[0m query \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;124mselect * from May2015\u001B[39m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124mwhere subreddit = \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpolitics\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m----> 5\u001B[0m politics \u001B[38;5;241m=\u001B[39m \u001B[43msimple_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[2], line 25\u001B[0m, in \u001B[0;36msimple_query\u001B[1;34m(query, params)\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21msimple_query\u001B[39m(query, params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;66;03m# optional params for easy sanitized inputs\u001B[39;00m\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;66;03m# use ? in query to pass variables safely into query\u001B[39;00m\n\u001B[0;32m     23\u001B[0m     \u001B[38;5;66;03m# pass params as list of variable names to be passed to query\u001B[39;00m\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;66;03m# results are pandas df\u001B[39;00m\n\u001B[1;32m---> 25\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mcon\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mfetchdf()\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Query interrupted"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T02:20:08.455251Z",
     "start_time": "2025-11-01T02:20:08.034933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(politics.shape)\n",
    "politics.memory_usage(deep=True).sum()/(1024 ** 2)"
   ],
   "id": "b6ce9a21a5512b9f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(244927, 22)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(308.6400547027588)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 151
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T01:49:24.186777Z",
     "start_time": "2025-11-01T01:49:22.743703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def decode(x):\n",
    "    if isinstance(x, (bytes, bytearray)):\n",
    "        return x.decode(\"utf-8\", errors=\"ignore\")\n",
    "    else:\n",
    "        return x\n",
    "politics_df = politics.copy(deep=True)\n",
    "\n",
    "for col in politics_df.columns:\n",
    "    politics_df[col] = politics_df[col].apply(decode)\n",
    "\n",
    "politics_df[\"created_utc\"] = pd.to_datetime(politics_df[\"created_utc\"], unit=\"s\", utc=True)\n"
   ],
   "id": "57a747943daf88df",
   "outputs": [],
   "execution_count": 135
  },
  {
   "cell_type": "code",
   "id": "62c0f2b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T01:50:20.300240Z",
     "start_time": "2025-11-01T01:50:19.774362Z"
    }
   },
   "source": [
    "# saves movies dataframe to parquet\n",
    "politics_df.to_parquet('../data/politics_subreddit.parquet', engine='pyarrow', index=False, compression='snappy')\n",
    "politics_df.head()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                created_utc  ups subreddit_id    link_id        name  \\\n",
       "0 2015-05-01 00:00:00+00:00    0     t5_2cneq  t3_34f7mc  t1_cqug90i   \n",
       "1 2015-05-01 00:00:06+00:00   -1     t5_2cneq  t3_34fn91  t1_cqug95d   \n",
       "2 2015-05-01 00:00:24+00:00    1     t5_2cneq  t3_34ebvj  t1_cqug9j2   \n",
       "3 2015-05-01 00:00:33+00:00    1     t5_2cneq  t3_34a6iq  t1_cqug9p6   \n",
       "4 2015-05-01 00:00:50+00:00    2     t5_2cneq  t3_34e3wn  t1_cquga2u   \n",
       "\n",
       "  score_hidden author_flair_css_class author_flair_text subreddit       id  \\\n",
       "0            0                   <NA>              <NA>  politics  cqug90i   \n",
       "1            0                   <NA>              <NA>  politics  cqug95d   \n",
       "2            0                   <NA>              <NA>  politics  cqug9j2   \n",
       "3            0                   <NA>              <NA>  politics  cqug9p6   \n",
       "4            0                   <NA>              <NA>  politics  cquga2u   \n",
       "\n",
       "   ... downs  archived              author score retrieved_on  \\\n",
       "0  ...     0         0        Wicked_Truth     0   1432703079   \n",
       "1  ...     0         0  OceanGroovedropper    -1   1432703081   \n",
       "2  ...     0         0          Drooperdoo     1   1432703086   \n",
       "3  ...     0         0          PabloNueve     1   1432703088   \n",
       "4  ...     0         0           whosename     2   1432703093   \n",
       "\n",
       "                                                body  distinguished edited  \\\n",
       "0  Are you really implying we return to those tim...           <NA>      0   \n",
       "1  Seems morally questionable to me, but if that'...           <NA>      0   \n",
       "2  Ah, Ninjew, we feel the same.\\n\\nWait! Nin*jew...           <NA>      0   \n",
       "3  I mean I suppose we'll find out. I just have n...           <NA>      0   \n",
       "4  Nor should you be able to.    \\nWould you like...           <NA>      0   \n",
       "\n",
       "  controversiality   parent_id  \n",
       "0                0  t1_cqufim0  \n",
       "1                0  t1_cqufu3n  \n",
       "2                0  t1_cqug1n2  \n",
       "3                0  t1_cqtsyye  \n",
       "4                0  t1_cqu59v3  \n",
       "\n",
       "[5 rows x 22 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>ups</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>name</th>\n",
       "      <th>score_hidden</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>downs</th>\n",
       "      <th>archived</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>body</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>edited</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-01 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>t3_34f7mc</td>\n",
       "      <td>t1_cqug90i</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>politics</td>\n",
       "      <td>cqug90i</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Wicked_Truth</td>\n",
       "      <td>0</td>\n",
       "      <td>1432703079</td>\n",
       "      <td>Are you really implying we return to those tim...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_cqufim0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-01 00:00:06+00:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>t3_34fn91</td>\n",
       "      <td>t1_cqug95d</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>politics</td>\n",
       "      <td>cqug95d</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>OceanGroovedropper</td>\n",
       "      <td>-1</td>\n",
       "      <td>1432703081</td>\n",
       "      <td>Seems morally questionable to me, but if that'...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_cqufu3n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-01 00:00:24+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>t3_34ebvj</td>\n",
       "      <td>t1_cqug9j2</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>politics</td>\n",
       "      <td>cqug9j2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Drooperdoo</td>\n",
       "      <td>1</td>\n",
       "      <td>1432703086</td>\n",
       "      <td>Ah, Ninjew, we feel the same.\\n\\nWait! Nin*jew...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_cqug1n2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-01 00:00:33+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>t3_34a6iq</td>\n",
       "      <td>t1_cqug9p6</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>politics</td>\n",
       "      <td>cqug9p6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PabloNueve</td>\n",
       "      <td>1</td>\n",
       "      <td>1432703088</td>\n",
       "      <td>I mean I suppose we'll find out. I just have n...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_cqtsyye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-01 00:00:50+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>t3_34e3wn</td>\n",
       "      <td>t1_cquga2u</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>politics</td>\n",
       "      <td>cquga2u</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>whosename</td>\n",
       "      <td>2</td>\n",
       "      <td>1432703093</td>\n",
       "      <td>Nor should you be able to.    \\nWould you like...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_cqu59v3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 138
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Analysis",
   "id": "788c9fb6d3f63d0f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T05:23:05.681282Z",
     "start_time": "2025-11-01T05:23:05.258935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "politics_df = pd.read_parquet('../data/politics_subreddit.parquet', engine=\"pyarrow\")\n",
    "politics_df.head()"
   ],
   "id": "62c6c3702c9b8fd7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                created_utc  ups subreddit_id    link_id        name  \\\n",
       "0 2015-05-01 00:00:00+00:00    0     t5_2cneq  t3_34f7mc  t1_cqug90i   \n",
       "1 2015-05-01 00:00:06+00:00   -1     t5_2cneq  t3_34fn91  t1_cqug95d   \n",
       "2 2015-05-01 00:00:24+00:00    1     t5_2cneq  t3_34ebvj  t1_cqug9j2   \n",
       "3 2015-05-01 00:00:33+00:00    1     t5_2cneq  t3_34a6iq  t1_cqug9p6   \n",
       "4 2015-05-01 00:00:50+00:00    2     t5_2cneq  t3_34e3wn  t1_cquga2u   \n",
       "\n",
       "  score_hidden author_flair_css_class author_flair_text subreddit       id  \\\n",
       "0            0                   None              None  politics  cqug90i   \n",
       "1            0                   None              None  politics  cqug95d   \n",
       "2            0                   None              None  politics  cqug9j2   \n",
       "3            0                   None              None  politics  cqug9p6   \n",
       "4            0                   None              None  politics  cquga2u   \n",
       "\n",
       "   ... downs  archived              author score retrieved_on  \\\n",
       "0  ...     0         0        Wicked_Truth     0   1432703079   \n",
       "1  ...     0         0  OceanGroovedropper    -1   1432703081   \n",
       "2  ...     0         0          Drooperdoo     1   1432703086   \n",
       "3  ...     0         0          PabloNueve     1   1432703088   \n",
       "4  ...     0         0           whosename     2   1432703093   \n",
       "\n",
       "                                                body  distinguished edited  \\\n",
       "0  Are you really implying we return to those tim...           None      0   \n",
       "1  Seems morally questionable to me, but if that'...           None      0   \n",
       "2  Ah, Ninjew, we feel the same.\\n\\nWait! Nin*jew...           None      0   \n",
       "3  I mean I suppose we'll find out. I just have n...           None      0   \n",
       "4  Nor should you be able to.    \\nWould you like...           None      0   \n",
       "\n",
       "  controversiality   parent_id  \n",
       "0                0  t1_cqufim0  \n",
       "1                0  t1_cqufu3n  \n",
       "2                0  t1_cqug1n2  \n",
       "3                0  t1_cqtsyye  \n",
       "4                0  t1_cqu59v3  \n",
       "\n",
       "[5 rows x 22 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>ups</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>name</th>\n",
       "      <th>score_hidden</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>downs</th>\n",
       "      <th>archived</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>body</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>edited</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-01 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>t3_34f7mc</td>\n",
       "      <td>t1_cqug90i</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>politics</td>\n",
       "      <td>cqug90i</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Wicked_Truth</td>\n",
       "      <td>0</td>\n",
       "      <td>1432703079</td>\n",
       "      <td>Are you really implying we return to those tim...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_cqufim0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-01 00:00:06+00:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>t3_34fn91</td>\n",
       "      <td>t1_cqug95d</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>politics</td>\n",
       "      <td>cqug95d</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>OceanGroovedropper</td>\n",
       "      <td>-1</td>\n",
       "      <td>1432703081</td>\n",
       "      <td>Seems morally questionable to me, but if that'...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_cqufu3n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-01 00:00:24+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>t3_34ebvj</td>\n",
       "      <td>t1_cqug9j2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>politics</td>\n",
       "      <td>cqug9j2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Drooperdoo</td>\n",
       "      <td>1</td>\n",
       "      <td>1432703086</td>\n",
       "      <td>Ah, Ninjew, we feel the same.\\n\\nWait! Nin*jew...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_cqug1n2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-01 00:00:33+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>t3_34a6iq</td>\n",
       "      <td>t1_cqug9p6</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>politics</td>\n",
       "      <td>cqug9p6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PabloNueve</td>\n",
       "      <td>1</td>\n",
       "      <td>1432703088</td>\n",
       "      <td>I mean I suppose we'll find out. I just have n...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_cqtsyye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-01 00:00:50+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>t3_34e3wn</td>\n",
       "      <td>t1_cquga2u</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>politics</td>\n",
       "      <td>cquga2u</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>whosename</td>\n",
       "      <td>2</td>\n",
       "      <td>1432703093</td>\n",
       "      <td>Nor should you be able to.    \\nWould you like...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_cqu59v3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T05:23:07.213262Z",
     "start_time": "2025-11-01T05:23:07.169080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cols = [\"created_utc\", \"ups\", \"downs\", \"score\", \"subreddit\", \"author\", \"body\", \"parent_id\", \"link_id\",'id']\n",
    "df = politics_df[cols].sort_values(\"created_utc\")"
   ],
   "id": "c4c66b4b1b95ea18",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T05:23:18.384067Z",
     "start_time": "2025-11-01T05:23:09.218217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "### Cleaning\n",
    "df = df[df[\"author\"].notnull()]\n",
    "df = df[~df[\"author\"].isin([\"[deleted]\", \"AutoModerator\"])]\n",
    "\n",
    "### Adding features\n",
    "df[\"body_len\"] = df[\"body\"].str.len().fillna(0)\n",
    "df[\"time_diff\"] = df.groupby(\"author\")[\"created_utc\"].diff().dt.total_seconds()\n",
    "\n",
    "features = df.groupby(\"author\").agg({\n",
    "    \"id\": \"count\",        # total comments\n",
    "    \"ups\": \"mean\",         #upvotes\n",
    "    \"downs\": \"mean\",        #downvotes\n",
    "    \"score\": \"mean\",\n",
    "    \"body_len\": \"mean\",     #avg post length\n",
    "    \"time_diff\": \"median\"  # posting frequency\n",
    "}).reset_index()\n",
    "\n",
    "features.columns = [\"author\", \"n_comments\", \"avg_ups\", \"avg_downs\", \"avg_score\", \"avg_body_len\", \"median_time_diff\"]\n",
    "\n",
    "\n",
    "\n",
    "# text features\n",
    "def lexical_diversity(texts):\n",
    "    tokens = re.findall(r'\\b\\w+\\b', ' '.join(texts).lower())\n",
    "    if not tokens:\n",
    "        return 0\n",
    "    return len(set(tokens)) / len(tokens)\n",
    "\n",
    "word_diversity = (\n",
    "    df.groupby('author')['body']\n",
    "    .apply(lexical_diversity)\n",
    "    .reset_index(name='lexical_diversity')\n",
    ")\n",
    "\n",
    "\n",
    "# temporal features\n",
    "df['hour'] = df['created_utc'].dt.hour\n",
    "hour_counts = df.groupby(['author', 'hour']).size().unstack(fill_value=0)\n",
    "hour_fraction = hour_counts.div(hour_counts.sum(axis=1), axis=0)\n",
    "\n",
    "def entropy(p):\n",
    "    p = p[p > 0]\n",
    "    return -np.sum(p * np.log2(p))\n",
    "\n",
    "hour_features = pd.DataFrame({\n",
    "    'author': hour_fraction.index,\n",
    "    'active_hours': (hour_fraction > 0).sum(axis=1),\n",
    "    'activity_entropy': hour_fraction.apply(entropy, axis=1)\n",
    "})\n",
    "\n",
    "\n",
    "# merge\n",
    "\n",
    "word_diversity = word_diversity.reset_index(drop=True)\n",
    "hour_features = hour_features.reset_index(drop=True)\n",
    "features = features.reset_index(drop=True)\n",
    "\n",
    "user_features = (\n",
    "    features\n",
    "    .merge(word_diversity, on=\"author\", how=\"outer\")\n",
    "    .merge(hour_features, on=\"author\", how=\"outer\")\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "\n",
    "# language modeling\n",
    "'''\n",
    "text_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "def avg_similarity(texts):\n",
    "    if len(texts) < 2:\n",
    "        return np.nan\n",
    "    embeddings = text_model.encode(texts, show_progress_bar=False)\n",
    "    sims = np.inner(embeddings, embeddings)\n",
    "    upper = np.triu_indices_from(sims, k=1)\n",
    "    return sims[upper].mean()\n",
    "\n",
    "text_similarity = (\n",
    "    df.groupby('author')['body']\n",
    "    .apply(lambda x: avg_similarity(x.sample(min(len(x), 50), random_state=42)))  # limit to 50 per author\n",
    "    .reset_index(name='avg_text_similarity')\n",
    ")\n",
    "'''\n",
    "df.shape"
   ],
   "id": "7b8088ec35796be8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229108, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T05:23:20.711788Z",
     "start_time": "2025-11-01T05:23:20.191503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# graph creation\n",
    "\n",
    "# Extract author and parent info\n",
    "comments = df[['author', 'parent_id', 'id']].copy()\n",
    "\n",
    "# remove t1/2/3_ from id\n",
    "comments['parent_id_clean'] = comments['parent_id'].str.replace(r'^t\\d_', '', regex=True)\n",
    "comments['id_clean'] = comments['id'].str.replace(r'^t\\d_', '', regex=True)\n",
    "\n",
    "#\n",
    "merged = comments.merge(\n",
    "    comments[['id_clean', 'author']],\n",
    "    left_on='parent_id_clean',\n",
    "    right_on='id_clean',\n",
    "    how='left',\n",
    "    suffixes=('', '_parent')\n",
    ")\n",
    "\n",
    "# drop duplicates and self connections\n",
    "edges = merged.dropna(subset=['author', 'author_parent'])\n",
    "edges = edges[edges['author'] != edges['author_parent']]\n",
    "\n",
    "G = nx.from_pandas_edgelist(edges, 'author', 'author_parent', create_using=nx.DiGraph())\n",
    "\n",
    "print(G.number_of_nodes(), \"users\")\n",
    "print(G.number_of_edges(), \"reply edges\")"
   ],
   "id": "eb2b7e034dd32e76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32846 users\n",
      "131491 reply edges\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DOMINANT model",
   "id": "36048557660e8728"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T05:23:25.603633Z",
     "start_time": "2025-11-01T05:23:24.541924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prepare graph\n",
    "data = from_networkx(G)\n",
    "\n",
    "X = np.array([\n",
    "    [G.nodes[n].get('lexical_diversity', 0),\n",
    "     G.nodes[n].get('active_hours', 0),\n",
    "     G.nodes[n].get('activity_entropy', 0),\n",
    "     G.nodes[n].get('avg_text_similarity', 0)]\n",
    "    for n in G.nodes\n",
    "], dtype=np.float32)\n",
    "\n",
    "data.x = torch.tensor(X)\n",
    "data.edge_index = data.edge_index\n"
   ],
   "id": "b66ad1a01570e00",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T05:23:27.696540Z",
     "start_time": "2025-11-01T05:23:27.668352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DOMINANT\n",
    "\n",
    "class DOMINANT(torch.nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim=64, embedding_dim=32):\n",
    "        super().__init__()\n",
    "        self.gc1 = GCNConv(in_dim, hidden_dim)\n",
    "        self.gc2 = GCNConv(hidden_dim, embedding_dim)\n",
    "\n",
    "        # Decoders\n",
    "        self.decoder_feat = torch.nn.Linear(embedding_dim, in_dim)\n",
    "        self.decoder_adj = torch.nn.Linear(embedding_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        z = F.relu(self.gc1(x, edge_index))\n",
    "        z = self.gc2(z, edge_index)\n",
    "\n",
    "        # Feature reconstruction\n",
    "        x_hat = self.decoder_feat(z)\n",
    "\n",
    "        # Adjacency reconstruction via dot product in embedding space\n",
    "        adj_hat = torch.sigmoid(torch.mm(z, z.t()))\n",
    "\n",
    "        return z, x_hat, adj_hat"
   ],
   "id": "a175763d5d877c0b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T05:34:44.617408Z",
     "start_time": "2025-11-01T05:23:31.077509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "adj_true = to_dense_adj(data.edge_index)[0]\n",
    "\n",
    "model = DOMINANT(in_dim=data.x.shape[1])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "lambda_adj = 0.5  # balance between feature and structure reconstruction\n",
    "\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z, x_hat, adj_hat = model(data.x, data.edge_index)\n",
    "\n",
    "    loss_feat = F.mse_loss(x_hat, data.x)\n",
    "    loss_adj = F.mse_loss(adj_hat, adj_true)\n",
    "    loss = loss_feat + lambda_adj * loss_adj\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch:03d}, Total Loss: {loss.item():.4f}\")"
   ],
   "id": "4b1c8fbe9fe48339",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000, Total Loss: 0.1341\n",
      "Epoch 020, Total Loss: 0.1252\n",
      "Epoch 040, Total Loss: 0.1250\n",
      "Epoch 060, Total Loss: 0.1250\n",
      "Epoch 080, Total Loss: 0.1250\n",
      "Epoch 100, Total Loss: 0.1250\n",
      "Epoch 120, Total Loss: 0.1250\n",
      "Epoch 140, Total Loss: 0.1250\n",
      "Epoch 160, Total Loss: 0.1250\n",
      "Epoch 180, Total Loss: 0.1250\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T05:34:54.260062Z",
     "start_time": "2025-11-01T05:34:51.875518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    z, x_hat, adj_hat = model(data.x, data.edge_index)\n",
    "\n",
    "# Feature reconstruction error\n",
    "feat_error = torch.mean((data.x - x_hat) ** 2, dim=1)\n",
    "\n",
    "# Structural reconstruction error (optional)\n",
    "adj_error = torch.mean((adj_true - adj_hat) ** 2, dim=1)\n",
    "\n",
    "# Combined anomaly score\n",
    "anomaly_score = feat_error + lambda_adj * adj_error\n",
    "\n",
    "# Add to graph or dataframe\n",
    "import pandas as pd\n",
    "\n",
    "scores_df = pd.DataFrame({\n",
    "    'author': list(G.nodes),\n",
    "    'anomaly_score': anomaly_score.cpu().numpy()\n",
    "}).sort_values('anomaly_score', ascending=False)\n",
    "\n",
    "print(scores_df.head(10))"
   ],
   "id": "a33a5dc7da53bfc4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  author  anomaly_score\n",
      "32845         Wobistdu99          0.125\n",
      "0                dafones          0.125\n",
      "1       ScreamForSilence          0.125\n",
      "2      you_get_CMV_delta          0.125\n",
      "3           SaggyBallsHD          0.125\n",
      "4           Kakarot_faps          0.125\n",
      "5           MadCervantes          0.125\n",
      "6             OHMYCARROT          0.125\n",
      "7          rickeyspanish          0.125\n",
      "8            comrade-jim          0.125\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T05:39:00.931306Z",
     "start_time": "2025-11-01T05:35:03.623682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "top_users = scores_df.head(30)['author']\n",
    "node_colors = [\n",
    "    'red' if n in top_users.values else 'lightgray'\n",
    "    for n in G.nodes\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "nx.draw(G, pos, node_color=node_colors, node_size=40, edge_color='gray', alpha=0.5)\n",
    "plt.title(\"Red = Top 30 Likely Bots\")\n",
    "plt.show()"
   ],
   "id": "31832480a049c48c",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 8\u001B[0m\n\u001B[0;32m      2\u001B[0m node_colors \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mred\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m top_users\u001B[38;5;241m.\u001B[39mvalues \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlightgray\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m G\u001B[38;5;241m.\u001B[39mnodes\n\u001B[0;32m      5\u001B[0m ]\n\u001B[0;32m      7\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m8\u001B[39m))\n\u001B[1;32m----> 8\u001B[0m pos \u001B[38;5;241m=\u001B[39m \u001B[43mnx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mspring_layout\u001B[49m\u001B[43m(\u001B[49m\u001B[43mG\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m42\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m nx\u001B[38;5;241m.\u001B[39mdraw(G, pos, node_color\u001B[38;5;241m=\u001B[39mnode_colors, node_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m40\u001B[39m, edge_color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgray\u001B[39m\u001B[38;5;124m'\u001B[39m, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m)\n\u001B[0;32m     10\u001B[0m plt\u001B[38;5;241m.\u001B[39mtitle(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRed = Top 30 Anomalous (Likely Bots)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\bot_detection\\lib\\site-packages\\networkx\\utils\\decorators.py:788\u001B[0m, in \u001B[0;36margmap.__call__.<locals>.func\u001B[1;34m(_argmap__wrapper, *args, **kwargs)\u001B[0m\n\u001B[0;32m    787\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mfunc\u001B[39m(\u001B[38;5;241m*\u001B[39margs, __wrapper\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 788\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m argmap\u001B[38;5;241m.\u001B[39m_lazy_compile(__wrapper)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m<class 'networkx.utils.decorators.argmap'> compilation 16:4\u001B[0m, in \u001B[0;36margmap_spring_layout_13\u001B[1;34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mcollections\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mgzip\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01minspect\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mitertools\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mre\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\bot_detection\\lib\\site-packages\\networkx\\drawing\\layout.py:486\u001B[0m, in \u001B[0;36mspring_layout\u001B[1;34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001B[0m\n\u001B[0;32m    484\u001B[0m         nnodes, _ \u001B[38;5;241m=\u001B[39m A\u001B[38;5;241m.\u001B[39mshape\n\u001B[0;32m    485\u001B[0m         k \u001B[38;5;241m=\u001B[39m dom_size \u001B[38;5;241m/\u001B[39m np\u001B[38;5;241m.\u001B[39msqrt(nnodes)\n\u001B[1;32m--> 486\u001B[0m     pos \u001B[38;5;241m=\u001B[39m \u001B[43m_sparse_fruchterman_reingold\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    487\u001B[0m \u001B[43m        \u001B[49m\u001B[43mA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_arr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfixed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterations\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mthreshold\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[0;32m    490\u001B[0m     A \u001B[38;5;241m=\u001B[39m nx\u001B[38;5;241m.\u001B[39mto_numpy_array(G, weight\u001B[38;5;241m=\u001B[39mweight)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\bot_detection\\lib\\site-packages\\networkx\\utils\\decorators.py:788\u001B[0m, in \u001B[0;36margmap.__call__.<locals>.func\u001B[1;34m(_argmap__wrapper, *args, **kwargs)\u001B[0m\n\u001B[0;32m    787\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mfunc\u001B[39m(\u001B[38;5;241m*\u001B[39margs, __wrapper\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 788\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m argmap\u001B[38;5;241m.\u001B[39m_lazy_compile(__wrapper)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m<class 'networkx.utils.decorators.argmap'> compilation 24:4\u001B[0m, in \u001B[0;36margmap__sparse_fruchterman_reingold_21\u001B[1;34m(A, k, pos, fixed, iterations, threshold, dim, seed)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mcollections\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mgzip\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01minspect\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mitertools\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mre\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\bot_detection\\lib\\site-packages\\networkx\\drawing\\layout.py:627\u001B[0m, in \u001B[0;36m_sparse_fruchterman_reingold\u001B[1;34m(A, k, pos, fixed, iterations, threshold, dim, seed)\u001B[0m\n\u001B[0;32m    625\u001B[0m     Ai \u001B[38;5;241m=\u001B[39m A\u001B[38;5;241m.\u001B[39mgetrowview(i)\u001B[38;5;241m.\u001B[39mtoarray()  \u001B[38;5;66;03m# TODO: revisit w/ sparse 1D container\u001B[39;00m\n\u001B[0;32m    626\u001B[0m     \u001B[38;5;66;03m# displacement \"force\"\u001B[39;00m\n\u001B[1;32m--> 627\u001B[0m     displacement[:, i] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43m(\u001B[49m\n\u001B[0;32m    628\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdelta\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdistance\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mAi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdistance\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    629\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    630\u001B[0m \u001B[38;5;66;03m# update positions\u001B[39;00m\n\u001B[0;32m    631\u001B[0m length \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msqrt((displacement\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39msum(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m))\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\bot_detection\\lib\\site-packages\\numpy\\_core\\_methods.py:50\u001B[0m, in \u001B[0;36m_sum\u001B[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001B[0m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_amin\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m     47\u001B[0m           initial\u001B[38;5;241m=\u001B[39m_NoValue, where\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m umr_minimum(a, axis, \u001B[38;5;28;01mNone\u001B[39;00m, out, keepdims, initial, where)\n\u001B[1;32m---> 50\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_sum\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m     51\u001B[0m          initial\u001B[38;5;241m=\u001B[39m_NoValue, where\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_prod\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m     55\u001B[0m           initial\u001B[38;5;241m=\u001B[39m_NoValue, where\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
